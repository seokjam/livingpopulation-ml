{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f7625f",
   "metadata": {},
   "source": [
    "# 안녕하세요^^ \n",
    "\n",
    "# AI 모델링 시간에 오신 여러분을 환영합니다.\n",
    "\n",
    "## 오늘은 날씨, 미세먼지, 공휴일 데이터를 활용하여 서울시 <u>생활인구</u>를 예측해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d774e",
   "metadata": {},
   "source": [
    "<img src = \"https://images.unsplash.com/photo-1546874177-9e664107314e?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1000&q=80\" width=100% align=\"center\"/>\n",
    "\n",
    "\n",
    "<div align=\"right\">Photo by <a href=\"https://unsplash.com/@yohoney?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Yohan Cho</a> on <a href=\"https://unsplash.com/photos/Mwvhyd22Lyw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\" >Unsplash</a></div>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1edbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bf9b7",
   "metadata": {},
   "source": [
    "# Chapter3. AI 모델링\n",
    "### **1) 실습 순서**\n",
    "- 환경 준비\n",
    "- Train, Test 데이터셋 분할\n",
    "- 데이터 정규화 (MinMaxScaler)\n",
    "- 머신러닝 모델 구현\n",
    "- 머신러닝 성능 평가\n",
    "- 결과 예측하기\n",
    "\n",
    "### **2) 실습 내용**\n",
    "\n",
    "- 대상 데이터를 읽어와 탐색하며 이해합니다.\n",
    "- 데이터에서 Feature와 Target을 분리합니다.\n",
    "- 데이터를 학습용 데이터와 평가용 데이터로 분리합니다.\n",
    "- Feature Scaling 작업을 통해 변수들의 범위를 일정한 수준으로 조정합니다.\n",
    "- 다양한 머신러닝 알고리즘을 사용해 모델링합니다.\n",
    "- 성능 평가 결과를 이해하고 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92637c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcc7c8",
   "metadata": {},
   "source": [
    "## 0. 환경 준비\n",
    "> **① 필요 라이브러리 불러오기** <br>\n",
    "> **② 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e00977",
   "metadata": {},
   "source": [
    "### **① 필요한 라이브러리 불러오기**\n",
    "- **pandas** : 데이터를 처리하고 분석하는데 효과적인 패키지\n",
    "- **matplotlib** : 데이터를 차트나 플롯으로 그려주는 시각화 라이브러리 패키지\n",
    "- **seaborn** : matplolib을 기반으로 다양한 색상 테마와 통계용 차트 등의 기능을 추가한 시각화 패키지\n",
    "- **sklearn** : 파이썬에서 머신러닝 분석을 할 때 유용하게 사용할 수 있는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 입력하세요.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "sns.set(font=\"Malgun Gothic\",#\"NanumGothicCoding\", \n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0baa2d",
   "metadata": {},
   "source": [
    "### **② 데이터 불러오기** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하고 결과를 확인합니다.\n",
    "df = pd.read_csv(\"./data/PREPROCESSING_LOCAL_PEOPLE_2017_2019.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ca1a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79441e24",
   "metadata": {},
   "source": [
    "## 1. Train, Test  데이터셋 분할\n",
    "> **① Feature / Target 데이터 분리하기** <br>\n",
    "> **② Train(학습용) / Test(검증용) 데이터 셋 나누기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2978a7",
   "metadata": {},
   "source": [
    "#### __① Feature / Target 데이터 분리__\n",
    "- Feature는 X, Target은 y로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e234244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature는 Target('총생활인구수') 제외한 나머지 \n",
    "x = df.drop(columns=['총생활인구수']).values\n",
    "\n",
    "# Target은 '총생활인구수'\n",
    "y = df['총생활인구수'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e653b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552ce90",
   "metadata": {},
   "source": [
    "#### __② Train / Test 데이터 Set 나누기__\n",
    "- x, y 값을 가지고 7:3 비율로 Train, Test 을 나누세요.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2fade9",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/pXAfX.png\" width=600> \n",
    "\n",
    "<div align=\"right\">Image by <a href=\"https://datascience.stackexchange.com/questions/61467/clarification-on-train-test-and-val-and-how-to-use-implement-it\">\"clarification on train, test and val and how to use\"</a> on <a href=\"https://datascience.stackexchange.com/\" >datascience.stackexchange</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23df45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 Set 나누기 (Train:Test = 7:3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8d0de",
   "metadata": {},
   "source": [
    "## 2. 데이터 스케일링\n",
    "\n",
    "입력 변수(Feature)들의 값을 일정한 수준으로 맞춰 주는 것은 Feature Scalining 이라 합니다.<br> \n",
    "데이터 스케일링의 목적은 컬럼 별 차이를 왜곡하지 않고 공통 척도로 변경하기 위함입니다. <br>\n",
    "가령 아래처럼 나이의 범위는 (0 ~ 100) 이고 , 소득의 범위는 (0 ~ 10,000,000) 이라고 하면 소득은 나이의 약 100,000배이며 범위의 Range도 넓습니다.<br> \n",
    "이 데이터를 그대로 사용하면 소득을 본질적으로 더 큰 값이기 때문에 나이 피쳐보다 더 큰 영향을 미치게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb0e63",
   "metadata": {},
   "source": [
    "#### __① MinMax Scaler (정규화)__\n",
    "- Min-Max Scaling은 모든 피처가 정확하게 [0,1] 사이에 위치하도록 데이터를 변경한다.\n",
    "<img src=\"https://ashutoshtripathicom.files.wordpress.com/2021/06/image-3.png\" width=600>\n",
    "\n",
    "<div align=\"right\">Image by <a href=\"https://ashutoshtripathi.com/2021/06/12/what-is-feature-scaling-in-machine-learning-normalization-vs-standardization/\">\"WHAT IS FEATURE SCALING IN MACHINE LEARNING\"</a> on <a href=\"https://ashutoshtripathi.com/\" >Data Science Duniya</a></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674abc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 스케일러 호출\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 스케일링 (Train, Test)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c161738",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-expansion",
   "metadata": {},
   "source": [
    "## 3. 머신러닝 모델 구현\n",
    "> **① 단일 모델**\n",
    ">> - *선형회귀(LinearRegression)*\n",
    ">> - *K-최근접 이웃 회귀 (K-NN Regression)*\n",
    ">> - *의사결정나무(DecisionTree)*\n",
    "\n",
    "> **② 앙상블(Ensemble) 모델** \n",
    ">> - *배깅(Bagging) : RandomForest*\n",
    ">> - *부스팅(Boosting) : XGBoost*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b26261",
   "metadata": {},
   "source": [
    "#### __① 단일 모델__\n",
    "##### - __선형 회귀(Linear Regression)__\n",
    "\n",
    "선형 회귀는 알려진 다른 관련 데이터 값을 사용하여 알 수 없는 데이터의 값을 예측하는 데이터 분석 기법입니다. 알 수 없는 변수 또는 종속 변수와 알려진 변수 또는 독립 변수를 선형 방정식으로 수학적으로 모델링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264bf5a",
   "metadata": {},
   "source": [
    "__[라이브러리 임포트]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e745a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0925b7",
   "metadata": {},
   "source": [
    "__[모델 학습하기]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d2e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 학습하기\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffe752",
   "metadata": {},
   "source": [
    "__[모델 예측하기]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기\n",
    "lr_predict = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f6dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lr_model.score(x_train, y_train)) \n",
    "print(lr_model.score(x_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc59192",
   "metadata": {},
   "source": [
    "__[모델 성능 평가하기]__<br>\n",
    "회귀모델에서는 얼마나 정확하게 예측을 했는지가 중요합니다. 동일하게 예측하는 것이 가장 좋겠지만, 그렇지 않을 경우 실제값과 가장 가깝게 예측한 모델이 성능이 좋은 모델입니다.<br>\n",
    "따라서, 성능평가를 위해서는 실제값과 예측값을 비교해야 합니다. \n",
    "> * __MAE (Mean Absolute Error)__<br>\n",
    "> 실제값과 예측값의 차이를 절댓값에 관한 평균<br>\n",
    "> * __MSE (Mean Squared Error)__<br>\n",
    "> 실제값과 예측값의 차이를 제곱한 값들의 평균\n",
    "> * __RMSE (Root Mean Squared Error)__<br>\n",
    "> 오류의 크기를 줄이기 위해 MSE 에 루트를 씌운 값\n",
    "> * __R2 Score (Coefficient of Determination )__<br>\n",
    "> 분산 기반의 평가 지표로, 1에 가까울 수록 좋은 모델이라고 할 수 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2-Score'])\n",
    "pd.set_option('display.float_format', '{:.5f}'.format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f501d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 성능 평가하기\n",
    "lr_mae = mean_absolute_error(y_test, lr_predict)\n",
    "lr_mse = mean_squared_error(y_test, lr_predict)\n",
    "lr_rmse = (mean_squared_error(y_test,lr_predict))*(1/2)\n",
    "lr_r2 = r2_score(y_test,lr_predict)\n",
    "\n",
    "print('LinearRegression')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(lr_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(lr_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(lr_rmse))\n",
    "print(\"r2-Score : \",lr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = model_evaluation.append({'Model' : 'Linear', \n",
    "                         'MAE' : lr_mae, \n",
    "                         'MSE' : lr_mse, \n",
    "                         'RMSE' : lr_rmse, \n",
    "                         'R2-Score' : lr_r2}, ignore_index=True)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be81856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(y_test[-100:], color='r')\n",
    "plt.plot(lr_predict[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2737ea67",
   "metadata": {},
   "source": [
    "##### - __K-최근접 이웃 회귀 (K-NN Regression)__\n",
    "\n",
    "K-NN Regression(K-최근접 이웃 회귀) 알고리즘은 주변의 가장 가까운 K개의 샘플을 통해 값을 예측하는 방식이다. 예를 들어 가장 간단한 방식으로는 K개 샘플의 평균을 이용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073671d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 모델 불러오기\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "# 모델 학습하기\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "# 예측하기\n",
    "knn_predict = knn_model.predict(x_test)\n",
    "\n",
    "# 성능 평가하기\n",
    "knn_mae = mean_absolute_error(y_test, knn_predict)\n",
    "knn_mse = mean_squared_error(y_test, knn_predict)\n",
    "knn_rmse = (mean_squared_error(y_test,knn_predict))*(1/2)\n",
    "knn_r2 = r2_score(y_test,knn_predict)\n",
    "\n",
    "print('K-NN Regression')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(knn_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(knn_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(knn_rmse))\n",
    "print(\"r2-Score : \",knn_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e561d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = model_evaluation.append({'Model' : 'K-NN', \n",
    "                         'MAE' : knn_mae, \n",
    "                         'MSE' : knn_mse, \n",
    "                         'RMSE' : knn_rmse, \n",
    "                         'R2-Score' : knn_r2}, ignore_index=True)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c831a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(y_test[-100:], color='r')\n",
    "plt.plot(knn_predict[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7695aa2",
   "metadata": {},
   "source": [
    "##### - __의사결정나무(DecisionTree)__\n",
    "\n",
    "주어진 입력값들의 조합에 대한 의사결정규칙(rule)에 따라 출력값을 예측하는 모형으로 트리구조의 그래프로 표현할 수 있습니다. 의사결정나무모형의 예측력은 다른 지도학습 기법들에 비해 대체로 떨어지나 해석이 수월하다는 장점이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ebd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 모델 불러오기\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# 모델 학습하기\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# 예측하기\n",
    "dt_predict = dt_model.predict(x_test)\n",
    "\n",
    "# 성능 평가하기\n",
    "dt_mae = mean_absolute_error(y_test, dt_predict)\n",
    "dt_mse = mean_squared_error(y_test, dt_predict)\n",
    "dt_rmse = (mean_squared_error(y_test,dt_predict))*(1/2)\n",
    "dt_r2 = r2_score(y_test,dt_predict)\n",
    "\n",
    "print('DecistionTree Regression')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(dt_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(dt_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(dt_rmse))\n",
    "print(\"r2-Score : \",dt_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8aa22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = model_evaluation.append({'Model' : 'DecistionTree', \n",
    "                         'MAE' : dt_mae, \n",
    "                         'MSE' : dt_mse, \n",
    "                         'RMSE' : dt_rmse, \n",
    "                         'R2-Score' : dt_r2}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acdd1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a93ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(y_test[-100:], color='r')\n",
    "plt.plot(dt_predict[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743bff2e",
   "metadata": {},
   "source": [
    "#### __② 앙상블(Essenble) 모델__\n",
    "- 배깅(Bagging) : Bootstrap aggregation을 줄여 bagging이라고 부른다. Bootstrap으로 생성된 sample data sets 각각으로 모델을 만든 뒤 모델의 평균값으로 예측을 하는 방법. 대표적으로 랜덤 포레스트(Random Forest) 모델이 있습니다.\n",
    "\n",
    "- 부스팅 (Boosting): 성능이 약한 학습기를 여러개 연결하여 순차적으로 학습을 하되, 이전 학습에 대하여 잘못 예측된 데이터에 가중치를 부여해 오차를 보완해 나가는 방식. 대표적으로 XGBoost, LGBM 등이 있습니다.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://itwiki.kr/images/f/f8/%EB%B0%B0%EA%B9%85%28Bagging%29.png\" width=300>\n",
    "        </td>\n",
    "         <td>\n",
    "            <img src=\"https://itwiki.kr/images/4/45/%EB%B6%80%EC%8A%A4%ED%8C%85%28Boosting%29.png\" width=300>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<div align=\"right\">Image by <a href=\"https://itwiki.kr/w/%EC%95%99%EC%83%81%EB%B8%94_%EA%B8%B0%EB%B2%95\">앙상블 기법</a> on <a href=\"https://itwiki.kr/\" >IT Wiki</a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f061f5",
   "metadata": {},
   "source": [
    "##### - __랜덤 포레스트(Random Forest)__\n",
    "\n",
    "Bagging 대표적인 모델로써, 훈련셋트를 무작위로 각기 다른 서브셋으로 데이터셋을 만들고<br>\n",
    "여러개의 DecisonTree로 학습하고 다수결로 결정하는 모델\n",
    "\n",
    "> **주요 Hyperparameter**\n",
    "> - random_state: 랜덤 시드 고정 값. 고정해두고 튜닝할 것!\n",
    "> - n_jobs: CPU 사용 갯수\n",
    "> - max_depth: 깊어질 수 있는 최대 깊이. 과대적합 방지용\n",
    "> - n_estimators: 앙상블하는 트리의 갯수\n",
    "> - max_features: 최대로 사용할 feature의 갯수. 과대적합 방지용\n",
    "> - min_samples_split: 트리가 분할할 때 최소 샘플의 갯수. default=2. 과대적합 방지용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 모델 불러오기\n",
    "rfc_model = RandomForestRegressor()\n",
    "\n",
    "# 모델 학습하기\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "# 예측하기\n",
    "rfc_predict = rfc_model.predict(x_test)\n",
    "\n",
    "# 성능 평가하기\n",
    "rfc_mae = mean_absolute_error(y_test, rfc_predict)\n",
    "rfc_mse = mean_squared_error(y_test, rfc_predict)\n",
    "rfc_rmse = (mean_squared_error(y_test,rfc_predict))*(1/2)\n",
    "rfc_r2 = r2_score(y_test,rfc_predict)\n",
    "\n",
    "print('RandomForest Regression')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(rfc_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(rfc_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(rfc_rmse))\n",
    "print(\"r2-Score : \",rfc_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892b72d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_evaluation = model_evaluation.append({'Model' : 'RandomForest', \n",
    "                         'MAE' : rfc_mae, \n",
    "                         'MSE' : rfc_mse, \n",
    "                         'RMSE' : rfc_rmse, \n",
    "                         'R2-Score' : rfc_r2}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = pd.concat(pd.DataFrame({'Model' : 'RandomForest', \n",
    "                         'MAE' : rfc_mae, \n",
    "                         'MSE' : rfc_mse, \n",
    "                         'RMSE' : rfc_rmse, \n",
    "                         'R2-Score' : rfc_r2})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f75dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f075bb",
   "metadata": {},
   "source": [
    "##### - __XGBoost(Extreme Gradient Boosting)__\n",
    "\n",
    "여러개의 DecisionTree를 결합하여 Strong Learner 만드는 Boosting 앙상블 기법<br>\n",
    "Kaggle 대회에서 자주 사용하는 모델이다.<br>\n",
    "\n",
    "> **주요 특징**\n",
    "> - scikit-learn 패키지가 아닙니다.\n",
    "> - 성능이 우수함\n",
    "> - 학습시간이 오래 걸립니다.\n",
    "\n",
    "> **주요 Hyperparameter**\n",
    "> - random_state: 랜덤 시드 고정 값. 고정해두고 튜닝할 것!\n",
    "> - n_jobs: CPU 사용 갯수\n",
    "> - learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1\n",
    "> - n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100\n",
    "> - max_depth: 트리의 깊이. 과대적합 방지용. default=3. \n",
    "> - subsample: 샘플 사용 비율. 과대적합 방지용. default=1.0\n",
    "> - max_features: 최대로 사용할 feature의 비율. 과대적합 방지용. default=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33fe6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 패키지 설치\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71206f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 모델 불러오기\n",
    "xgb_model = XGBRegressor()  \n",
    "\n",
    "# 모델 학습하기\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# 예측하기\n",
    "xgb_predict = xgb_model.predict(x_test)\n",
    "\n",
    "# 성능 평가하기\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_predict)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_predict)\n",
    "xgb_rmse = (mean_squared_error(y_test,xgb_predict))*(1/2)\n",
    "xgb_r2 = r2_score(y_test,xgb_predict)\n",
    "\n",
    "print('XGBoost Regression')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(xgb_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(xgb_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(xgb_rmse))\n",
    "print(\"r2-Score : \",xgb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,20))\n",
    "plt.plot(y_test[-24:], color='r')\n",
    "plt.plot(xgb_predict[-24:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b06848",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = model_evaluation.append({'Model' : 'XGBoost', \n",
    "                         'MAE' : xgb_mae, \n",
    "                         'MSE' : xgb_mse, \n",
    "                         'RMSE' : xgb_rmse, \n",
    "                         'R2-Score' : xgb_r2}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20c6c3",
   "metadata": {},
   "source": [
    "## 4. 머신러닝 모델 성능 비교하기\n",
    "> **① 모델 성능 비교하기** <br>\n",
    "> **② 변수 중요도(Feature Importance) 확인하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eaad3b",
   "metadata": {},
   "source": [
    "#### __① 모델 성능 비교하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845bf33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb811ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "fig.suptitle('Model Evaluation')\n",
    "\n",
    "# MAE\n",
    "sns.barplot(ax=axes[0], x=model_evaluation['MAE'], y=model_evaluation['Model'])\n",
    "axes[0].set_title(\"MAE\")\n",
    "\n",
    "# RMSE\n",
    "sns.barplot(ax=axes[1], x=model_evaluation['RMSE'], y=model_evaluation['Model'])\n",
    "axes[1].set_title(\"RMSE\")\n",
    "\n",
    "# R2-Score\n",
    "sns.barplot(ax=axes[2], x=model_evaluation['R2-Score'], y=model_evaluation['Model'])\n",
    "axes[2].set_title('R2-Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69367c",
   "metadata": {},
   "source": [
    "#### __② 변수 중요도(Feature Importance) 확인하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df.drop(columns=['총생활인구수'])\n",
    "\n",
    "xgb_importances_values = xgb_model.feature_importances_\n",
    "xgb_importances = pd.Series(xgb_importances_values, index = feature.columns)\n",
    "xgb_top10 = xgb_importances.sort_values(ascending=False)[:10]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('XGB Top 10 Feature Importances')\n",
    "sns.barplot(x=xgb_top10, y=xgb_top10.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f21ba2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfc_importances_values = rfc_model.feature_importances_\n",
    "rfc_importances = pd.Series(rfc_importances_values, index = feature.columns)\n",
    "rfc_top10 = rfc_importances.sort_values(ascending=False)[:10]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('RFC Top 10 Feature Importances')\n",
    "sns.barplot(x=rfc_top10, y=rfc_top10.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758136b1",
   "metadata": {},
   "source": [
    "## 4. 모델 저장하기\n",
    "> **① 학습시킨 모델 저장하기** <br>\n",
    "> **② 저장한 모델 불러와서 사용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a1d00",
   "metadata": {},
   "source": [
    "#### __① 학습시킨 모델 저장하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d64b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ebd9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import joblib\n",
    "\n",
    "#model 저장\n",
    "joblib.dump(xgb_model,'./model/LOCAL_PEOPLE.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc7c07",
   "metadata": {},
   "source": [
    "#### __② 저장한 모델 불러와서 사용하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc091949",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = joblib.load('./model/LOCAL_PEOPLE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17821e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021 = pd.read_csv('./data/test/TEST_LOCAL_PEOPLE_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ada02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies를 활용하여 범주형 데이터 가변수화 진행\n",
    "df_2021 = pd.get_dummies(df_2021, columns=['Month', 'Day', '요일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature는 Target('총생활인구수') 제외한 나머지 \n",
    "x_2021 = df_2021.drop(columns=['총생활인구수']).values\n",
    "\n",
    "# Target은 '총생활인구수'\n",
    "y_2021 = df_2021['총생활인구수'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링하기\n",
    "x_2021 = scaler.transform(x_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc68ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 모델로 예측하기\n",
    "predict_2021 = load_model.predict(x_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ea0e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 새로운 데이터 기준으로 성능 평가하기\n",
    "model_mae = mean_absolute_error(y_2021, predict_2021)\n",
    "model_mse = mean_squared_error(y_2021, predict_2021)\n",
    "model_rmse = (mean_squared_error(y_2021,predict_2021))*(1/2)\n",
    "model_r2 = r2_score(y_2021,predict_2021)\n",
    "\n",
    "print('XGBoost Regression')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(model_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(model_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(model_rmse))\n",
    "print(\"r2-Score : \",model_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59be65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,20))\n",
    "plt.plot(y_2021, color='r')\n",
    "plt.plot(predict_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707f965",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73526a5",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> [실습]</font> \n",
    "앞선 실습 과정에서 배운 머신러닝 모델 중 어떤 것이든 좋습니다. 원하는 모델을 선택해서 학습을 시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e5c8f",
   "metadata": {},
   "source": [
    "__<font color=red>[Q]</font> '총생활인구수'를 y(target)으로 하고 나머지 컬럼을 x(feature)로 만드세요.__\n",
    "- target 변수:Y, feature 변수:X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafa90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 입력하세요.\n",
    "X = df.drop(columns=['총생활인구수']).values\n",
    "Y = df['총생활인구수'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a98f09",
   "metadata": {},
   "source": [
    "#### __<font color='red'>[Q]</font> x와 y 값을 가지고 8:2 비율로 Train, Test 데이터 셋을 나누세요.__\n",
    "- train 데이터 셋 : X_train, Y_train<br>\n",
    "- test 데이터 셋 : X_test, Y_test<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8082e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 입력하세요.\n",
    "\n",
    "# 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 Set 나누기 (Train:Test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,  test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e06bf8",
   "metadata": {},
   "source": [
    "#### __<font color='red'>[Q]</font> 사이킷런의 MinMaxScaler를 활용하여 x_train, x_test 데이터를 정규화 하세요.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9c329",
   "metadata": {},
   "source": [
    "#### __<font color='red'>[Q]</font> 원하는 모델을 선택하고 아래의 조건으로 학습을 시켜 보세요.__\n",
    "- 모델 변수명은 'self_model'로 저장하세요.\n",
    "- mae, rmse, r2-score 성능 지표를 사용하여 모델을 평가해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기에 입력하세요.\n",
    "# 라이브러리 임포트\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 모델 불러오기\n",
    "self_model = RandomForestRegressor(max_depth=10, n_estimators=100, random_state=32)\n",
    "\n",
    "# 모델 학습하기\n",
    "self_model.fit(X_train, Y_train)\n",
    "\n",
    "# 예측하기\n",
    "self_predict = self_model.predict(X_test)\n",
    "\n",
    "# 성능 평가하기\n",
    "self_mae = mean_absolute_error(Y_test, self_predict)\n",
    "self_mse = mean_squared_error(Y_test, self_predict)\n",
    "self_rmse = (mean_squared_error(Y_test,self_predict))*(1/2)\n",
    "self_r2 = r2_score(Y_test,self_predict)\n",
    "\n",
    "print('Self Model Evaluation')\n",
    "print(\"Mean Absolute Error : {0:.5f}\".format(self_mae))\n",
    "print(\"Mean Squared Error : {0:.5f}\".format(self_mse))\n",
    "print(\"Root Mean Squared Error : {0:.5f}\".format(self_rmse))\n",
    "print(\"r2-Score : \",self_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446221a",
   "metadata": {},
   "source": [
    "#### __<font color='red'>[Q]</font> 학습이 완료된 모델을 저장해 보세요.__\n",
    "- 모델 저장 파일명은 'self_model.pkl'로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed843ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 실습해 보세요.\n",
    "# 라이브러리 임포트\n",
    "import joblib\n",
    "\n",
    "#model 저장\n",
    "joblib.dump(self_model,'./model/self_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
